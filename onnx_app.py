import gradio as gr
import argparse
import os
import cv2
from tqdm import tqdm
import numpy as np
import onnxruntime as ort

def check_folder(path):
    if not os.path.exists(path):
        os.makedirs(path)
    return path

def process_image(img, x32=True):
    h, w = img.shape[:2]
    if x32: # resize image to multiple of 32s
        def to_32s(x):
            return 256 if x < 256 else x - x%32
        img = cv2.resize(img, (to_32s(w), to_32s(h)))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)/ 127.5 - 1.0
    return img

def post_precess(img, wh):
    img = (img.squeeze() + 1.0) / 2 * 255
    img = img.astype(np.uint8)
    img = cv2.resize(img, (wh[0], wh[1]))
    return img

def cvt2anime_video(video_path, output, model, onnx = 'model.onnx', output_format='mp4v'):  # å°å†™å°±ä¸æŠ¥é”™äº†ï¼Œåªæ˜¯ä»ç„¶æ— æ³•åœ¨æµè§ˆå™¨ä¸Šæ’­æ”¾

    # check onnx model
    exists = os.path.isfile(onnx)
    if not exists:
        print('Model file not found:', onnx)
        return

    # åŠ è½½æ¨¡å‹ï¼Œè‹¥æœ‰ GPU, åˆ™ç”¨ GPU æ¨ç†
    # å‚è€ƒï¼šhttps://zhuanlan.zhihu.com/p/645720587
    # æ…å…¥ï¼https://zhuanlan.zhihu.com/p/492040015
    if ort.get_device()=='GPU':
        print('use gpu')
        providers = ['CUDAExecutionProvider','CPUExecutionProvider',]
        session = ort.InferenceSession(onnx, providers=providers)
        session.set_providers(['CUDAExecutionProvider'], [ {'device_id': 0}]) #gpu 0
    else:
        print('use cpu')
        providers = ['CPUExecutionProvider',]
        session = ort.InferenceSession(onnx, providers=providers)

    input_name = session.get_inputs()[0].name

    # load video
    video_in = cv2.VideoCapture(video_path)
    video_in_name = os.path.basename(video_path)  # åªå–æ–‡ä»¶å
    # https://blog.csdn.net/lsoxvxe/article/details/131999217
    # https://pythonjishu.com/python-os-28/

    total = int(video_in.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = int(video_in.get(cv2.CAP_PROP_FPS))
    width = int(video_in.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(video_in.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fourcc = cv2.VideoWriter_fourcc(*output_format)

    # è¾“å‡ºè§†é¢‘åç§°ã€è·¯å¾„
    video_out_name = video_in_name.rsplit('.', 1)[0] + '_' + model + '.mp4'
    video_out_path = os.path.join(output, video_out_name)

    video_out = cv2.VideoWriter(video_out_path, fourcc, fps, (width, height))

    pbar = tqdm(total=total, ncols=80)
    pbar.set_description(f"Making: {video_out_name}")

    while True:
        ret, frame = video_in.read()
        if not ret:
            break
        # frame = np.expand_dims(process_image(frame),0)
        frame = np.asarray(np.expand_dims(process_image(frame), 0))
        fake_img = session.run(None, {input_name : frame})
        fake_img = post_precess(fake_img[0], (width, height))
        video_out.write(cv2.cvtColor(fake_img, cv2.COLOR_BGR2RGB))
        pbar.update(1)

    pbar.close()
    video_in.release()
    video_out.release()

    return video_out_path


def anime(video_filepath, style):
    try:
        output = "output"
        check_folder(output) # ç©ºæ–‡ä»¶å¤¹çœŸçƒ¦äºº

        model = "H64_model0"
        if style == "ã€Šèµ·é£äº†ã€‹ï¼ˆå®«å´éªï¼‰":
            model = "H64_model0"
        elif style == "ç´ æ":
            model = "PortraitSketch_25"
        elif style == "æ—¥æ¼«è„¸":
            model = "JP_face_v1.0"

        onnx = os.path.join("pb_and_onnx_model", "AnimeGANv3_" + model + ".onnx")

        try:
            output_filepath = cvt2anime_video(video_filepath, output, model, onnx)
            return output_filepath
        except RuntimeError as error:
            print('Error', error)
    except Exception as error:
        print('global exception', error)
        return None, None

title = "è®°å½•å¼å½±ç‰‡è¿ç§»åŠ¨æ¼«åˆ›ä½œå¹³å°"
description = r"""ç›®å‰ï¼Œå¾ˆå¤šçºªå½•å¼ç”µå½±ç‰‡æ®µå…·æœ‰å¾ˆæ·±çš„æ•™è‚²æ„ä¹‰ï¼Œç„¶è€Œè¿™äº›å½±ç‰‡å¾€å¾€è¶£å‘³æ€§è¾ƒä½ï¼Œå¯¹äºé’å°‘å¹´å—ä¼—ç¾¤ä½“å°¤ç”šï¼›è€ŒåŠ¨æ¼«é£æ ¼å¤šå˜ï¼Œè‰²å½©ä¸°å¯Œï¼Œä¸»è§’å½¢ä½“ã€è¯­éŸ³éƒ½å…·æœ‰éå¸¸å¤§çš„ä¸°å¯Œæ€§ã€‚<br>
åŠ¨æ¼«æ˜¯æˆ‘ä»¬æ—¥å¸¸ç”Ÿæ´»ä¸­å¸¸è§çš„è‰ºæœ¯å½¢å¼ï¼Œè¢«å¹¿æ³›åº”ç”¨äºå¹¿å‘Šã€ç”µå½±å’Œå„¿ç«¥æ•™è‚²ç­‰å¤šä¸ªé¢†åŸŸã€‚ç›®å‰ï¼ŒåŠ¨æ¼«çš„åˆ¶ä½œä¸»è¦æ˜¯ä¾é æ‰‹å·¥å®ç°ã€‚<br>
ç„¶è€Œï¼Œæ‰‹å·¥åˆ¶ä½œåŠ¨æ¼«éå¸¸è´¹åŠ›ï¼Œéœ€è¦éå¸¸ä¸“ä¸šçš„è‰ºæœ¯æŠ€å·§ã€‚å¯¹äºåŠ¨æ¼«è‰ºæœ¯å®¶æ¥è¯´ï¼Œåˆ›ä½œé«˜è´¨é‡çš„åŠ¨æ¼«ä½œå“éœ€è¦ä»”ç»†è€ƒè™‘çº¿æ¡ã€çº¹ç†ã€é¢œè‰²å’Œé˜´å½±ï¼Œè¿™æ„å‘³ç€åˆ›ä½œåŠ¨æ¼«æ—¢å›°éš¾åˆè€—æ—¶ã€‚<br>
å› æ­¤ï¼Œèƒ½å¤Ÿå°†çœŸå®ä¸–ç•Œçš„ç…§ç‰‡ã€è§†é¢‘è‡ªåŠ¨è½¬æ¢ä¸ºé«˜è´¨é‡åŠ¨æ¼«é£æ ¼å›¾åƒçš„è‡ªåŠ¨æŠ€æœ¯æ˜¯éå¸¸æœ‰ä»·å€¼çš„ã€‚å®ƒä¸ä»…èƒ½è®©è‰ºæœ¯å®¶ä»¬æ›´å¤šä¸“æ³¨äºåˆ›é€ æ€§çš„å·¥ä½œï¼Œä¹Ÿèƒ½è®©æ™®é€šäººæ›´å®¹æ˜“åˆ›å»ºè‡ªå·±çš„åŠ¨æ¼«ä½œå“ã€‚ğŸ˜Š<br>
"""

demo = gr.Interface(
    fn=anime,
    inputs=[
        gr.Video(source="upload"),
        gr.Dropdown([
            'ã€Šèµ·é£äº†ã€‹ï¼ˆå®«å´éªï¼‰',  # Hayao
            'ç´ æ',  # PortraitSketch_25
            'æ—¥æ¼«è„¸',  # JP_face_v1.0
        ],
            type="value",  # é»˜è®¤
            value='ã€Šèµ·é£äº†ã€‹ï¼ˆå®«å´éªï¼‰',
            label='style'),
    ],
    outputs=[
        gr.PlayableVideo(),
    ],
    title=title,
    description=description,
    allow_flagging='never',
    examples=[
        ["examples/1.mp4", "ç´ æ"],
        ["examples/2.mp4", "ã€Šèµ·é£äº†ã€‹ï¼ˆå®«å´éªï¼‰"],
        ["examples/3.mp4", "æ—¥æ¼«è„¸"],
        ["examples/4.mp4", "ã€Šèµ·é£äº†ã€‹ï¼ˆå®«å´éªï¼‰"],
        ["examples/5.mp4", "ç´ æ"],
    ],
    cache_examples=True, # ç¼“å­˜ç¤ºä¾‹ä»¥å®ç°å¿«é€Ÿè¿è¡Œï¼Œå¦‚ä¿®æ”¹éœ€è¦æ‰‹åŠ¨åˆ é™¤
    )

if __name__ == "__main__":
    # https://www.gradio.app/guides/setting-up-a-demo-for-maximum-performance
    # queue æ–¹æ³•å…è®¸ç”¨æˆ·é€šè¿‡åˆ›å»ºä¸€ä¸ªé˜Ÿåˆ—æ¥æ§åˆ¶è¯·æ±‚çš„å¤„ç†é€Ÿç‡ï¼Œä»è€Œå®ç°æ›´å¥½çš„æ§åˆ¶ã€‚ç”¨æˆ·å¯ä»¥è®¾ç½®ä¸€æ¬¡å¤„ç†çš„è¯·æ±‚æ•°é‡ï¼Œå¹¶å‘ç”¨æˆ·æ˜¾ç¤ºä»–ä»¬åœ¨é˜Ÿåˆ—ä¸­çš„ä½ç½®ã€‚
    demo.launch(share=True, show_error=True)
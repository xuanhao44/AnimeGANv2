import os

import av
import cv2
import gradio as gr
import numpy as np
import onnxruntime as ort
from tqdm import tqdm


def check_folder(path):
    if not os.path.exists(path):
        os.makedirs(path)
    return path


def process_image_alter(img, x32=True):
    h, w = img.shape[:2]
    if x32:  # resize image to multiple of 32s
        def to_32s(x):
            return 256 if x < 256 else x - x % 32

        img = cv2.resize(img, (to_32s(w), to_32s(h)))
    img = img.astype(np.float32) / 127.5 - 1.0  # æ³¨æ„ä¿®æ”¹
    return img


def post_precess(img, wh):
    img = (img.squeeze() + 1.0) / 2 * 255
    img = img.astype(np.uint8)
    img = cv2.resize(img, (wh[0], wh[1]))
    return img


def cvt2anime_video(video_path, output, model, onnx='model.onnx'):
    # check onnx model
    exists = os.path.isfile(onnx)
    if not exists:
        print('Model file not found:', onnx)
        return

    # åŠ è½½æ¨¡å‹ï¼Œè‹¥æœ‰ GPU, åˆ™ç”¨ GPU æ¨ç†
    # å‚è€ƒï¼šhttps://zhuanlan.zhihu.com/p/645720587
    # æ…å…¥ï¼https://zhuanlan.zhihu.com/p/492040015
    if ort.get_device() == 'GPU':
        print('use gpu')
        providers = ['CUDAExecutionProvider', 'CPUExecutionProvider', ]
        session = ort.InferenceSession(onnx, providers=providers)
    else:
        print('use cpu')
        providers = ['CPUExecutionProvider', ]
        session = ort.InferenceSession(onnx, providers=providers)

    video_in_name = os.path.basename(video_path)  # åªå–æ–‡ä»¶å
    # è¾“å‡ºè§†é¢‘åç§°ã€è·¯å¾„
    video_out_name = video_in_name.rsplit('.', 1)[0] + '_' + model + '.mp4'
    video_out_path = os.path.join(output, video_out_name)

    # è½½å…¥è§†é¢‘
    in_container = av.open(video_path, 'r')
    in_video_stream = next(s for s in in_container.streams if s.type == 'video')
    in_audio_stream = next(s for s in in_container.streams if s.type == 'audio')

    fps = in_video_stream.base_rate  # å¸§ç‡
    width = in_video_stream.width  # å¸§å®½
    height = in_video_stream.height  # å¸§é«˜
    total_time_in_second = in_video_stream.duration * 1.0 * in_video_stream.time_base  # è§†é¢‘æ€»é•¿
    total_frame = int(total_time_in_second * fps)  # è§†é¢‘æ€»å¸§æ•°

    out_container = av.open(video_out_path, 'w')
    out_video_stream = out_container.add_stream("h264", rate=fps)
    out_audio_stream = out_container.add_stream(template=in_audio_stream)

    out_video_stream.width = width
    out_video_stream.height = height

    pbar = tqdm(total=total_frame, ncols=80)
    pbar.set_description(f"Making: {video_out_name}")

    for packet in in_container.demux(in_video_stream, in_audio_stream):

        _type = packet.stream.type

        for frame in packet.decode():
            if _type == 'video':
                frame = frame.to_ndarray(format="rgb24")  # è¿™é‡Œ frame å¾—åˆ°äº† rgb æ ¼å¼
                # https://www.zhihu.com/question/452884533 VideoCapture è¯»å‡ºæ¥çš„å›¾ç‰‡é»˜è®¤æ˜¯ BGR æ ¼å¼ï¼Œæ‰€ä»¥éœ€è¦è½¬
                # ä½†æ˜¯è¿™é‡Œ frame å¯ä»¥æŒ‡å®šæ ¼å¼ï¼Œæ‰€ä»¥åé¢å°±ä¿®æ”¹åŸæ¥çš„ process_image å‡½æ•°ï¼Œä¸ç”¨è½¬æ¢ cvtColor äº†ã€‚

                frame = np.asarray(np.expand_dims(process_image_alter(frame), 0))
                fake_img = session.run(None, {session.get_inputs()[0].name: frame})
                fake_img = post_precess(fake_img[0], (width, height))

                frame = av.VideoFrame.from_ndarray(fake_img, format="rgb24")  # æ¥æ”¶ rgb
                out_container.mux(out_video_stream.encode(frame))

                pbar.update(1)  # bar è·Ÿéš video frame

            elif _type == 'audio':
                # We need to skip the "flushing" packets that `demux` generates.
                if packet.dts is None:
                    continue
                # We need to assign the packet to the new stream.
                packet.stream = out_audio_stream
                out_container.mux(packet)

    pbar.close()

    # Close the file
    out_container.close()

    return video_out_path


def anime(video_filepath, style):
    try:
        output = "output"
        check_folder(output)  # ç©ºæ–‡ä»¶å¤¹çœŸçƒ¦äºº

        model = "H64_model0"
        if style == "ã€Šèµ·é£äº†ã€‹ï¼ˆå®«å´éªï¼‰":
            model = "H64_model0"
        elif style == "ç´ æ":
            model = "PortraitSketch_25"
        elif style == "æ—¥æ¼«è„¸":
            model = "JP_face_v1.0"

        onnx = os.path.join("pb_and_onnx_model", "AnimeGANv3_" + model + ".onnx")

        try:
            output_filepath = cvt2anime_video(video_filepath, output, model, onnx)
            return output_filepath
        except RuntimeError as error:
            print('Error', error)
    except Exception as error:
        print('global exception', error)
        return None, None


title = "è®°å½•å¼å½±ç‰‡è¿ç§»åŠ¨æ¼«åˆ›ä½œå¹³å°"
description = r"""ç›®å‰ï¼Œå¾ˆå¤šçºªå½•å¼ç”µå½±ç‰‡æ®µå…·æœ‰å¾ˆæ·±çš„æ•™è‚²æ„ä¹‰ï¼Œç„¶è€Œè¿™äº›å½±ç‰‡å¾€å¾€è¶£å‘³æ€§è¾ƒä½ï¼Œå¯¹äºé’å°‘å¹´å—ä¼—ç¾¤ä½“å°¤ç”šï¼›è€ŒåŠ¨æ¼«é£æ ¼å¤šå˜ï¼Œè‰²å½©ä¸°å¯Œï¼Œä¸»è§’å½¢ä½“ã€è¯­éŸ³éƒ½å…·æœ‰éå¸¸å¤§çš„ä¸°å¯Œæ€§ã€‚<br>
åŠ¨æ¼«æ˜¯æˆ‘ä»¬æ—¥å¸¸ç”Ÿæ´»ä¸­å¸¸è§çš„è‰ºæœ¯å½¢å¼ï¼Œè¢«å¹¿æ³›åº”ç”¨äºå¹¿å‘Šã€ç”µå½±å’Œå„¿ç«¥æ•™è‚²ç­‰å¤šä¸ªé¢†åŸŸã€‚ç›®å‰ï¼ŒåŠ¨æ¼«çš„åˆ¶ä½œä¸»è¦æ˜¯ä¾é æ‰‹å·¥å®ç°ã€‚<br>
ç„¶è€Œï¼Œæ‰‹å·¥åˆ¶ä½œåŠ¨æ¼«éå¸¸è´¹åŠ›ï¼Œéœ€è¦éå¸¸ä¸“ä¸šçš„è‰ºæœ¯æŠ€å·§ã€‚å¯¹äºåŠ¨æ¼«è‰ºæœ¯å®¶æ¥è¯´ï¼Œåˆ›ä½œé«˜è´¨é‡çš„åŠ¨æ¼«ä½œå“éœ€è¦ä»”ç»†è€ƒè™‘çº¿æ¡ã€çº¹ç†ã€é¢œè‰²å’Œé˜´å½±ï¼Œè¿™æ„å‘³ç€åˆ›ä½œåŠ¨æ¼«æ—¢å›°éš¾åˆè€—æ—¶ã€‚<br>
å› æ­¤ï¼Œèƒ½å¤Ÿå°†çœŸå®ä¸–ç•Œçš„ç…§ç‰‡ã€è§†é¢‘è‡ªåŠ¨è½¬æ¢ä¸ºé«˜è´¨é‡åŠ¨æ¼«é£æ ¼å›¾åƒçš„è‡ªåŠ¨æŠ€æœ¯æ˜¯éå¸¸æœ‰ä»·å€¼çš„ã€‚å®ƒä¸ä»…èƒ½è®©è‰ºæœ¯å®¶ä»¬æ›´å¤šä¸“æ³¨äºåˆ›é€ æ€§çš„å·¥ä½œï¼Œä¹Ÿèƒ½è®©æ™®é€šäººæ›´å®¹æ˜“åˆ›å»ºè‡ªå·±çš„åŠ¨æ¼«ä½œå“ã€‚ğŸ˜Š<br>
"""

demo = gr.Interface(
    fn=anime,
    inputs=[
        gr.Video(source="upload"),
        gr.Dropdown([
            'ã€Šèµ·é£äº†ã€‹ï¼ˆå®«å´éªï¼‰',  # H64_model0
            'ç´ æ',  # PortraitSketch_25
            'æ—¥æ¼«è„¸',  # JP_face_v1.0
        ],
            type="value",  # é»˜è®¤
            value='ã€Šèµ·é£äº†ã€‹ï¼ˆå®«å´éªï¼‰',
            label='style'),
    ],
    outputs=[
        gr.PlayableVideo(),
    ],
    title=title,
    description=description,
    allow_flagging='never',
    examples=[
        ["examples/1.mp4", "ç´ æ"],
        ["examples/2.mp4", "ã€Šèµ·é£äº†ã€‹ï¼ˆå®«å´éªï¼‰"],
        ["examples/3.mp4", "æ—¥æ¼«è„¸"],
        ["examples/4.mp4", "ã€Šèµ·é£äº†ã€‹ï¼ˆå®«å´éªï¼‰"],
        ["examples/5.mp4", "ç´ æ"],
    ],
    cache_examples=True,  # ç¼“å­˜ç¤ºä¾‹ä»¥å®ç°å¿«é€Ÿè¿è¡Œï¼Œå¦‚ä¿®æ”¹éœ€è¦æ‰‹åŠ¨åˆ é™¤
)

if __name__ == "__main__":
    # https://www.gradio.app/guides/setting-up-a-demo-for-maximum-performance
    # queue æ–¹æ³•å…è®¸ç”¨æˆ·é€šè¿‡åˆ›å»ºä¸€ä¸ªé˜Ÿåˆ—æ¥æ§åˆ¶è¯·æ±‚çš„å¤„ç†é€Ÿç‡ï¼Œä»è€Œå®ç°æ›´å¥½çš„æ§åˆ¶ã€‚ç”¨æˆ·å¯ä»¥è®¾ç½®ä¸€æ¬¡å¤„ç†çš„è¯·æ±‚æ•°é‡ï¼Œå¹¶å‘ç”¨æˆ·æ˜¾ç¤ºä»–ä»¬åœ¨é˜Ÿåˆ—ä¸­çš„ä½ç½®ã€‚
    demo.launch(share=True, show_error=True)
